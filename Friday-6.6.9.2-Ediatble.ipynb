{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Friday-6.6.9.2-Ediatble.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1rK8SbULOMot0ESjJLE99S8LpoeZBUcRw","authorship_tag":"ABX9TyNY2thdh0NUiAvB+Pz4rQb7"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"FisAjIK69PsY"},"source":["##Dependencies"]},{"cell_type":"code","metadata":{"id":"HJLDsgE0zu-I"},"source":["import os\n","import time\n","import json\n","import random\n","import datetime\n","\n","try:    \n","    import nltk\n","    import discord\n","    import numpy as np\n","    import tensorflow as tf\n","    from googlesearch import search\n","    from sklearn.tree import DecisionTreeClassifier\n","    \n","except ModuleNotFoundError:\n","    Dependencies = [\n","        \"nltk==3.2.5\",\n","        \"numpy==1.19.5\",\n","        \"scikit-learn==0.22.2.post1\",\n","        \"tensorflow==2.4.1\",\n","        \"google==2.0.3\",\n","        \"discord\"\n","    ]\n","    [os.system(f\"pip install {Dependency}\") for Dependency in Dependencies]\n","finally:\n","    import nltk\n","    import discord\n","    import numpy as np\n","    import tensorflow as tf\n","    from googlesearch import search\n","    from sklearn.tree import DecisionTreeClassifier\n","    os.system(\"python -m nltk.downloader all\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k-hGyswtz-wn"},"source":["##Utility Functions"]},{"cell_type":"code","metadata":{"id":"Z6MOOlht0Djg"},"source":["def timeit(method):\n","    def timed(*args, **kw):\n","        ts = time.time()\n","        result = method(*args, **kw)\n","        te = time.time()\n","        if \"log_time\" in kw:\n","            name = kw.get(\"log_name\", method.__name__.upper())\n","            kw[\"log_time\"][name] = int((te - ts) * 1000)\n","        else:\n","            print(\"%r  %2.2f ms\" % (method.__name__, (te - ts) * 1000))\n","        return result\n","\n","    return timed\n","\n","\n","def Encode(Text, Binary):\n","    with open(r\"/content/Friday.json\", \"r\") as f:\n","        data = json.loads(f.read())\n","\n","    tokens = nltk.RegexpTokenizer(r\"\\w+\").tokenize(Text.lower().strip())\n","    tags = [tag for word, tag in nltk.pos_tag(tokens)]\n","    encoded = [data[\"tags\"][tag] for tag in tags]\n","\n","    if len(encoded) > 51:\n","        encoded = encoded[:51]\n","    else:\n","        for i in range(51 - len(encoded)):\n","            encoded.append(0)\n","\n","    if Binary == False:\n","        return encoded\n","    elif Binary == True:\n","        tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=51)\n","        encoded = tokenizer.sequences_to_matrix([encoded], mode=\"binary\")\n","        return encoded[0].tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MT1PULaA0G3Q"},"source":["##Class: Data"]},{"cell_type":"code","metadata":{"id":"MhNWtGeDRBYL"},"source":["class Data:\n","    def __init__(self):\n","        pass\n"," \n","    #timeit\n","    def Create(self, BinaryFormat, Run):\n","        if Run == True:\n","            with open(r\"/content/Friday.json\", \"r\") as f:\n","                RawData = json.loads(f.read())\n"," \n","            TrainJson = RawData[\"Train\"]\n","            TestJson = RawData[\"Test\"]\n"," \n","            X = [Encode(comment, BinaryFormat) for comment in TrainJson]\n","            Y = [TrainJson[comment] for comment in TrainJson]\n","            x = [Encode(comment, BinaryFormat) for comment in TestJson]\n","            y = [TestJson[comment] for comment in TestJson]\n"," \n","            FridayData = {\"X\": X, \"Y\": Y, \"x\": x, \"y\": y}\n"," \n","            with open(r\"/content/Encoded.json\", \"w\") as f:\n","                json.dump(FridayData, f, indent=4)\n","        elif Run == False:\n","            pass\n"," \n","    #timeit\n","    def Get(self):\n","        with open(r\"/content/Encoded.json\", \"r\") as f:\n","            EncodedData = json.load(f)\n"," \n","        X = EncodedData[\"X\"]\n","        Y = EncodedData[\"Y\"]\n","        x = EncodedData[\"x\"]\n","        y = EncodedData[\"y\"]\n"," \n","        Classes = np.max(Y) + 1\n"," \n","        Y = tf.keras.utils.to_categorical(Y, Classes)\n","        y = tf.keras.utils.to_categorical(y, Classes)\n"," \n","        MaxWords = 51\n","        BatchSize = 256\n","        Epochs = 10\n"," \n","        return [X, Y, x, y, Classes, MaxWords, BatchSize, Epochs]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bSQo0ncI0NwM"},"source":["##Class: Predict"]},{"cell_type":"code","metadata":{"id":"P6I2u6tJZr07","cellView":"code"},"source":["class Predict:\n","    def __init__(self, Text, Create=False):\n","        self.Text = Encode(Text, True)\n","        Data().Create(BinaryFormat=True, Run=Create)\n","        [\n","            self.X,\n","            self.Y,\n","            self.x,\n","            self.y,\n","            self.Classes,\n","            self.MaxWords,\n","            self.BatchSize,\n","            self.Epochs,\n","        ] = Data().Get()\n","\n","    #timeit\n","    def Sklearn(self):\n","\n","        self.Prediction = (\n","            DecisionTreeClassifier().fit(self.X, self.Y).predict([self.Text])\n","        )\n","        return np.argmax(self.Prediction)\n","\n","class TF:\n","    def __init__(self, Create=False):\n","        Data().Create(BinaryFormat=True, Run=Create)\n","        [\n","            self.X,\n","            self.Y,\n","            self.x,\n","            self.y,\n","            self.Classes,\n","            self.MaxWords,\n","            self.BatchSize,\n","            self.Epochs,\n","        ] = Data().Get()\n","        self.model = tf.keras.models.Sequential(\n","            [\n","                tf.keras.layers.Dense(\n","                    self.MaxWords, input_shape=(self.MaxWords,), activation=\"tanh\"\n","                ),\n","                tf.keras.layers.Dense(2 * self.MaxWords, activation=\"tanh\"),\n","                tf.keras.layers.Dropout(0.2),\n","                tf.keras.layers.Dense(3, activation=\"softmax\"),\n","            ]\n","        )\n","        self.model.compile(\n","            optimizer=\"adam\", metrics=[\"accuracy\"], loss=\"categorical_crossentropy\"\n","        )\n","        self.model.fit(\n","            np.array(self.X),\n","            np.array(self.Y),\n","            batch_size=self.BatchSize,\n","            epochs=0,\n","            verbose=0,\n","        )\n","\n","    def Show(self, Text):\n","        self.Text = Encode(Text, True)\n","        self.Prediction = self.model.predict([self.Text])\n","        return np.argmax(self.Prediction)\n","\n","Predictor = TF(True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eTs-bbG0-wnu"},"source":["##Class: Responder"]},{"cell_type":"code","metadata":{"id":"Bm85ynbrCuyP"},"source":["class Response:\n","    def __init__(self, Text):\n","        self.Status = False\n","        self.Text = Text\n","\n","    def Native(self, Query):\n","        with open(r\"/content/Friday.json\", \"r\") as F:\n","            data = json.load(F)\n","\n","        for _ in data[\"questions\"]:\n","            if _ in Query.lower():\n","                for __ in data[\"questions\"][_]:\n","                    if __ in Query.lower():\n","                        for ___ in data[\"questions\"][_][__]:\n","                            if ___ in Query.lower():\n","                                return [data[\"questions\"][_][__][___], True]\n","        else:\n","            return [None, False]\n","\n","    def TimeBasedGreetings(self):\n","        with open(r\"/content/Friday.json\",\"r\") as f:\n","            Data = json.load(f)[\"sentences\"][\"TimeBasedGreetings\"]\n","        \n","        Hour = datetime.datetime.now().hour\n","        M,A,E,N = range(5,12),range(12,17),range(17,23),[23,24,0,1,2,3,4]\n","\n","        if Hour in M: return random.choice(Data[\"Morning\"])\n","        elif Hour in A: return random.choice(Data[\"Afternoon\"])\n","        elif Hour in E: return random.choice(Data[\"Evening\"])\n","        elif Hour in N: return random.choice(Data[\"Night\"])\n","        else: return random.choice(Data[\"None\"])\n","        \n","    def Main(self):\n","        try:\n","            self.Prediction = Predict(self.Text, False).Sklearn()\n","        except FileNotFoundError:\n","            self.Prediction = Predict(self.Text, True).Sklearn()\n","\n","        # self.Prediction = Predictor.Show(self.Text)\n","        \n","        with open(r\"/content/Friday.json\",\"r\") as f:\n","            data = json.load(f)\n","\n","        if self.Prediction == 0:\n","            with open(r\"/content/Log.txt\", \"a\") as F:\n","                F.write(f\"\\n{self.Text}\")\n","                return \"Logged That.\"\n","\n","        elif self.Prediction == 1:\n","            \n","            if datetime.datetime.now().hour in [23,24,0,1,2,3,4]:\n","                return self.TimeBasedGreetings()\n","            \n","            Native_Data = self.Native(Query=self.Text)\n","            if Native_Data[1] == True:\n","                self.Status = True\n","                return Native_Data[0]\n","\n","            for _ in data[\"sentences\"][\"greetings\"]:\n","                if self.Text.lower() in _ and _ in self.Text.lower():\n","                    return self.TimeBasedGreetings()\n","\n","            for _ in data[\"sentences\"][\"farewell\"]:\n","                if _ in self.Text.lower() or self.Text.lower() in _:\n","                    return random.choice(data[\"sentences\"][\"farewell_output\"])\n","\n","            else:\n","                return \"I can only recognize that this is a Statement, for now.\"\n","\n","        elif self.Prediction == 2:\n","            Native_Data = self.Native(self.Text)\n","            if Native_Data[1] == True:\n","                self.Status = True\n","                return Native_Data[0]\n","            else:\n","                for Result in search(self.Text, stop=1):\n","                    return Result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kHW-P4TFcF-Z"},"source":["##Class: Interface"]},{"cell_type":"code","metadata":{"id":"5vrmwSeCcI4A"},"source":["class Interface:\n","    def __init__(self):\n","        pass\n","\n","    def Terminal(self):\n","        while True:\n","            Text = input(\"[Input] : \")\n","            if Text == \"q\":\n","                raise KeyboardInterrupt\n","            print(\"[Response] :\", Response(Text).Main())\n","\n","    def Discord(self):\n","        pass\n","\n","Interface().Terminal()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uo66OM14ZWty"},"source":["# import nltk, string\n","# from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# class Similarity():\n","#     def __init__(self):\n","#         pass\n","\n","#     def Normalizer(self,text):\n","#         tokens = nltk.word_tokenize(text.lower().translate(dict((ord(char), None) for char in string.punctuation)))\n","#         return [nltk.stem.porter.PorterStemmer().stem(item) for item in tokens]\n","\n","#     def Check(self,text1, text2):\n","#         vectorizer = TfidfVectorizer(tokenizer=self.Normalizer, stop_words='english')\n","#         tfidf = vectorizer.fit_transform([text1, text2])\n","#         return ((tfidf * tfidf.T).A)[0,1]\n","\n","# print(Similarity().Check(\"morning\",\"good morning sweatheart\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xapVDXlTv3-6"},"source":["import datetime\n","import time\n","from IPython.display import clear_output\n","\n","while True:\n","    time.sleep(1)\n","    clear_output(wait=True)\n","    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))"],"execution_count":null,"outputs":[]}]}